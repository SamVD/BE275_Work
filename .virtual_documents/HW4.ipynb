


import scipy
import scipy.io
import numpy as np
from sklearn.metrics import r2_score
from sklearn.preprocessing import scale, StandardScaler
from sklearn.cross_decomposition import PLSRegression
from sklearn.model_selection import LeaveOneGroupOut, LeaveOneOut
import matplotlib.pyplot as plt
data = scipy.io.loadmat('wk4_Cosgrove-data.mat', squeeze_me=True)['s']
X = data['X'].item() # the untransformed data matrix (66x102)
Y = data['Y'].item() # the untransformed LDH release at 48hours. (66x1) (66 by (5 or take this array as one))
phosphoproteins = data['phosphoproteins'].item() # names of phosphoproteins(102x1)
conditions = data['conditions'].item() # cell array of the 66 conditions (66x1)
drugList = data['drugList'].item() # description of the drugs used in each of the 66 conditions (66x1)
drugListToxic = data['drugListToxic'].item() # binary value corresponding to whether drugList[i] is toxic (11x1)
drugs = data['drugs'].item() # binary matrix mapping which measurements correspond to a drug treatment in drugList (66x11)
cytokineList = data['cytokineList'].item() # cell array of cytokine treatments (6x1)
cytokines = data['cytokines'].item()
ind4pProtein = data['ind4pProtein'].item() # the column indices corresponding to measurements of the 4 phosphoprotein subset(24x1)





# Answer
X_S = scale(X)
print(X_S)
Y4 = Y[:,4]
Y_S = scale(Y4)
print(Y_S)
R2Y = []
#print(Y_S)
for n in range (1, 10):
    pls = PLSRegression(n_components = n, scale=True, max_iter=500, tol=1e-06, copy=True)
    pls.fit_transform(X_S, Y_S)
    r2 = pls.score(X_S, Y_S)
    R2Y = np.append(R2Y, r2)

pcas = np.arange(1,10,1)    
plt.plot(pcas,R2Y)
plt.xlabel("Number of PCAs")
plt.ylabel("R2Y value")
min90 = np.min(np.where(R2Y>=0.9))
min90 = min90 +1

print("Number of PCs required to reach 90% explanation of Y variance: " , min90)
print("Array of Percentage of variance in prediction explained by the sum of total PCAs: " , R2Y)














# Answer
#plot scores plots for X and Y (for PC1 and PC2) 
X_S = (X)
Y4 = Y[:,4]
Y_S = (Y4)
pls2 = PLSRegression(n_components = 2, scale=True, max_iter=500, tol=1e-06, copy=True)
pls2.fit_transform(X_S, Y_S)

xscores = pls2.x_scores_
yscores = pls2.y_scores_
pc1x = (xscores[:,0])
pc2x = xscores[:,1]
pc1y = (yscores[:,0])
pc2y = yscores[:,1]
#print((xscores))
drug_groups = np.zeros([66])
drug_groups_names = []
drug_groups_toxic = []
drug_colors = ['black', 'black', 'g', 'black' ,'lime' ,'black', 'darkorange' ,'black', 'darkviolet' ,'saddlebrown' ,'gray']
drug_color_map = []#np.empty([] , dtype = np.str_)
edge_shape_map = np.empty([66] , dtype = np.str_)

for m in range (0, np.size(pc1x)):
    c = (m //6)
    drug_groups[m] =  c+1
    drug_groups_names.append(drugList[c])
    drug_groups_toxic.append(drugListToxic[c])
    drug_color_map.append(drug_colors[c])
    

for k in range (0, np.size(drug_groups_toxic)):
    if drug_groups_toxic[k] == 1:
        edge_shape_map[k] = 'r'
    else:
         edge_shape_map[k] = 'b'
            
edge_list = edge_shape_map.tolist()

plt.figure(figsize = (20,20))
sobs = plt.scatter(pc1x, pc2x, s= 100 ,edgecolors = edge_list, c = drug_color_map)
#spred = plt.scatter(pc1y, pc2y, s = 100, marker = 'd' ,edgecolors = edge_list, c = drug_color_map )
for iii, label in enumerate(drug_groups_names):
    plt.annotate(label, (pc1x[iii], pc2x[iii]))

plt.tick_params(axis = 'x', labelsize = 14)
plt.tick_params(axis = 'y', labelsize = 14)
plt.xlabel('PC1', size = 30)
plt.ylabel('PC2', size = 30)
plt.axhline(0, color='gray')
plt.axvline(0, color='gray')
plt.title('Scores Diagram', size = 40)

plt.grid(True)









# Answer
X_S = scale(X)
Y4 = Y[:,4]
Y_S = scale(Y4)
pls2 = PLSRegression(n_components = 2, scale=True, max_iter=500, tol=1e-06, copy=True)
pls2.fit_transform(X_S, Y_S)

xloadings = pls2.x_loadings_
yloadings = pls2.y_loadings_
pc1xl = (xloadings[:,0])
pc2xl = xloadings[:,1]
pc1yl = (yloadings[:,0])
pc2yl = yloadings[:,1]
#print((xscores))


plt.figure()
var = plt.scatter(pc1xl, pc2xl)
pred = plt.scatter(pc1yl, pc2yl)
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.title("Loadings Plot")
plt.axhline(0, color='gray')
plt.axvline(0, color='gray')
plt.legend([var, pred], ['variables', 'predictions']);









# Answer.
from sklearn.utils import resample
pls2 = PLSRegression(n_components = 2, scale=True, max_iter=500, tol=1e-06, copy=True)

arr_pc1_xrl = np.zeros([102,1001])
arr_pc2_xrl = np.zeros([102,1001])
arr_pc1_yrl = np.zeros([1,1001])
arr_pc2_yrl = np.zeros([1,1001])

variance_pc1_xrl = np.zeros(102)
variance_pc2_xrl = np.zeros(102)
mean_pc1_xrl = np.zeros(102)
mean_pc2_xrl = np.zeros(102)
std_pc1_xrl = np.zeros(102)
std_pc2_xrl = np.zeros(102)


variance_pc1_yrl = np.zeros(1)
variance_pc2_yrl = np.zeros(1)
mean_pc1_yrl = np.zeros(1)
mean_pc2_yrl = np.zeros(1)
std_pc1_yrl = np.zeros(1)
std_pc2_yrl = np.zeros(1)


pcx0 = np.zeros(1001)
pcx02 = np.zeros([1,1001])
sumx0 = 0

ii=0
for ii in range (0,1001):
    X = data['X'].item()
    Y = data['Y'].item()
    Y4 = Y[:,4]
    resamp = resample(range(X.shape[0]))
    XR_S = X[resamp]; YR_S = Y4[resamp]
    pls2.fit_transform(XR_S, YR_S)
    xrloadings = pls2.x_loadings_
    yrloadings = pls2.y_loadings_
    pc1xlr = (xrloadings[:,0])
    pc2xlr = xrloadings[:,1]
    pc1ylr = (yrloadings[:,0])
    pc2ylr = yrloadings[:,1]
    nn=0
    mm=0
    for nn in range (0, np.size(pc1xlr)):
        arr_pc1_xrl[nn,ii] = pc1xlr[nn]
        arr_pc2_xrl[nn,ii] = pc2xlr[nn]

    for mm in range (0, np.size(pc1ylr)):
        arr_pc1_yrl[mm,ii] = pc1ylr
        arr_pc2_yrl[mm,ii] = pc2ylr   

rr=0       
for rr in range(0,102):
    variance_pc1_xrl[rr] = np.var(arr_pc1_xrl[rr,:])
    variance_pc2_xrl[rr] = np.var(arr_pc2_xrl[rr,:])
    std_pc1_xrl[rr] = np.std(arr_pc1_xrl[rr,:])
    std_pc2_xrl[rr] = np.std(arr_pc2_xrl[rr,:])
    mean_pc1_xrl[rr] = np.mean(arr_pc1_xrl[rr,:])
    mean_pc2_xrl[rr] = np.mean(arr_pc2_xrl[rr,:])
    
kk=0
for kk in range(0,1):
    variance_pc1_yrl[kk] = np.var(arr_pc1_yrl[kk,:])
    variance_pc2_yrl[kk] = np.var(arr_pc2_yrl[kk,:])
    std_pc1_yrl[kk] = np.std(arr_pc1_yrl[kk,:])
    std_pc2_yrl[kk] = np.std(arr_pc2_yrl[kk,:])
    mean_pc1_yrl[kk] = np.mean(arr_pc1_yrl[kk,:])
    mean_pc2_yrl[kk] = np.mean(arr_pc2_yrl[kk,:])   



    
plt.figure(figsize = (20,20))
meanplotx = plt.scatter(mean_pc1_xrl, mean_pc2_xrl)
varx = plt.errorbar(mean_pc1_xrl, mean_pc2_xrl, xerr = variance_pc1_xrl, yerr = variance_pc2_xrl, fmt ='none')
vary = plt.errorbar(mean_pc1_yrl, mean_pc2_yrl, xerr = variance_pc1_yrl, yerr = variance_pc2_yrl, fmt ='none', ecolor = 'r')
meanploty = plt.scatter(mean_pc1_yrl, mean_pc2_yrl)
#pred = plt.scatter(pc1yl, pc2yl)
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.title("Loadings Plot wit variance")
plt.axhline(0, color='gray')
plt.axvline(0, color='gray')
plt.legend([var, pred], ['variables', 'predictions'], labelcolor = ['b', 'r']);

plt.figure(figsize = (20,20))
meanplotx = plt.scatter(mean_pc1_xrl, mean_pc2_xrl)
stdx = plt.errorbar(mean_pc1_xrl, mean_pc2_xrl, xerr = std_pc1_xrl, yerr = std_pc2_xrl, fmt ='none')
stdy = plt.errorbar(mean_pc1_yrl, mean_pc2_yrl, xerr = std_pc1_yrl, yerr = std_pc2_yrl, fmt ='none', ecolor = 'r')
meanploty = plt.scatter(mean_pc1_yrl, mean_pc2_yrl)
#pred = plt.scatter(pc1yl, pc2yl)
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.title("Loadings Plot with standard deviation")
plt.axhline(0, color='gray')
plt.axvline(0, color='gray')
plt.legend([var, pred], ['variables', 'predictions'], labelcolor = ['b', 'r']);
    



 











# Answer
XX = X[:, ind4pProtein]
Y4 = Y[:,4]

pls4 = PLSRegression(n_components = 4, scale=True, max_iter=500, tol=1e-06, copy=True)
pls4.fit_transform(XX, Y4)
ypredicted = pls4.predict(XX)

ypredT = ypredicted.T
ypredTf = ypredT.reshape(66)

numer = ((((ypredTf - Y4)**2).sum()))
denom = (  (((ypredTf)**2).sum()) - (((ypredTf).sum())**2)/(np.size(Y[:,0])))
fitmody = 1 - (numer/denom)

print("R2 value calculated by using the formula given in the Cosgrove paper (equation in code):" , fitmody)

print("R2 value calculated by using the score function given in the partial least squares regression code from sklearn, uses 1 - (sum(Y4-self.predict(XX))^2 / sum((Y4 - mean(Y4))^2) : ", pls4.score(XX,Y4))


yr2 = r2_score(Y4, ypredicted)
print("R2 value calculated by using the score function given in the partial least squares regression code from sklearn, uses 1 - (sum((Y4-ypredicted)^2) / sum((Y4 - mean(Y4))^2) : " , yr2)



plt.figure()
# = plt.scatter(pc1xl, pc2xl)
ysc = plt.scatter(Y4, ypredicted)
#ytr = plt.scatter(
plt.xlabel("Observed LDH")
plt.ylabel("Predicted LDH")
plt.title("Observed vs. Predicted LDH")
plt.axhline(0, color='gray')
plt.axvline(0, color='gray');
#plt.legend([var, pred], ['variables', 'predictions']);







# Answer
from sklearn.model_selection import LeaveOneOut
leaveOO = LeaveOneOut()

XX = X[:, ind4pProtein]
print(XX)
Y4 = Y[:,4]
print(Y4)
leave_one_out_ind = np.arange(len(XX[:,0]))
predict_test_vals = np.zeros(len(XX[:,0]))

for train_index, test_index in leaveOO.split(leave_one_out_ind):
    trainXX = XX[train_index]
    trainY4 = Y4[train_index]
    pls4co = PLSRegression(n_components = 4, scale=True, max_iter=500, tol=1e-06, copy=True)
    pls4co.fit_transform(trainXX, trainY4)
    #print(pls4co.score(XX,Y4))
    predict_test_vals[test_index] = pls4co.predict(XX[test_index])

print("R2 score for the orginal data: ", pls4co.score(XX,Y4))
print()

#yr2cv = r2_score(Y4, predict_test_vals)
#print(yr2cv)
#print()

numer2 = ((((Y4 - predict_test_vals)**2).sum())**0.5)
denom2 = (((Y4)**2).sum())**0.5
fitmody2 = 1 - (numer2/denom2)       
print("R2Y correlation coefficient acording to class equation: ", fitmody2)
print()

numer = ((((predict_test_vals - Y4)**2).sum()))
denom = (  (((predict_test_vals)**2).sum()) - (((predict_test_vals).sum())**2)/(np.size(predict_test_vals)))
fitmody = 1 - (numer/denom)
print("R2Y Pearson correlation coefficient acording to paper equation: ",fitmody)
print()

numer2 = ((((Y4 - predict_test_vals)**2).sum()))
denom2 = (((Y4-np.mean(Y4))**2).sum())
fitmody3 = 1 - (numer2/denom2)       
print("R2Y correlation coefficient acording to sklearn equation: " , fitmody3)
print()



#cvloscore = pls4co.score(XX, predict_test_vals)
#print(cvloscore)
#print()


plt.figure()

ysc = plt.scatter(Y4, predict_test_vals)
plt.xlabel("Observed LDH")
plt.ylabel("Predicted LDH")
plt.title("Observed vs. Predicted LDH")
plt.axhline(0, color='gray')
plt.axvline(0, color='gray');   













data = scipy.io.loadmat('wk4_Cosgrove-data.mat', squeeze_me=True)['s']
cytokines = data['cytokines'].item()
cytogroups = np.zeros_like(cytokines)
groups = np.zeros_like(cytokines[:,0])
for rr in range(np.size(cytokines[:,0])):
    cc = 0
    while cc < np.size(cytokines[0,:]):
            if cytokines[rr,cc] == 1:
                groups[rr] = (cc+1)
                #cytogroups[rr,cc] = cc+1
                cc = cc+1
            else:
                cc = cc + 1         



# Answer
data = scipy.io.loadmat('wk4_Cosgrove-data.mat', squeeze_me=True)['s']
cytokineList = data['cytokineList'].item() # cell array of cytokine treatments (6x1)
cytokines = data['cytokines'].item()

from sklearn.model_selection import LeaveOneGroupOut
leaveOG = LeaveOneGroupOut()

leave_group_ind = np.arange(len(cytokines))

XX = X[:, ind4pProtein]
Y4 = Y[:,4]

print("Number of Groups: " ,leaveOG.get_n_splits(XX, Y4, groups))

predict_test_vals_cg = np.zeros([66,1])

for train_index, test_index in leaveOG.split(XX, Y4, groups):
    #print(train_index)
    trainXX = XX[train_index]
    trainY4 = Y4[train_index]
    pls4cg = PLSRegression(n_components = 4, scale=True, max_iter=500, tol=1e-06, copy=True)
    pls4cg.fit_transform(trainXX, trainY4)
    predict_test_vals_cg[test_index] = pls4cg.predict(XX[test_index])

predict_test_vals_rs = predict_test_vals.reshape(66)
#print(predict_test_vals_rs)


print("R2 score for the original data: " ,pls4cg.score( XX,Y4))
print()
#yr2cv = r2_score(Y4, predict_test_vals_rs)
#print(yr2cv) 


numer2 = ((((Y4 - predict_test_vals_rs)**2).sum())**0.5)
denom2 = (((Y4)**2).sum())**0.5
fitmody2 = 1 - (numer2/denom2)       
print("R2Y correlation coefficient acording to class equation: ", fitmody2)
print()

numer = ((((predict_test_vals_rs - Y4)**2).sum()))
denom = (  (((predict_test_vals_rs)**2).sum()) - (((predict_test_vals_rs).sum())**2)/(np.size(predict_test_vals_rs)))
fitmody = 1 - (numer/denom)
print("R2Y Pearson correlation coefficient acording to paper equation: ",fitmody)
print()



numer3 = ((((Y4 - predict_test_vals_rs)**2).sum()))
denom3 = (((Y4-np.mean(Y4))**2).sum())
fitmody3 = 1 - (numer3/denom3)       
print("R2Y correlation coefficient acording to sklearn equation: " , fitmody3)
print()


plt.figure()

ysc = plt.scatter(Y4, predict_test_vals_cg)
plt.xlabel("Observed LDH")
plt.ylabel("Predicted LDH")
plt.title("Observed vs. Predicted LDH")
plt.axhline(0, color='gray')
plt.axvline(0, color='gray');  
 



